{
  "best_metric": 0.24711766839027405,
  "best_model_checkpoint": "./trains/checkpoint-1000",
  "epoch": 4.0,
  "eval_steps": 100,
  "global_step": 1876,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021321961620469083,
      "grad_norm": 7.040177345275879,
      "learning_rate": 0.0001990405117270789,
      "loss": 0.8504,
      "step": 10
    },
    {
      "epoch": 0.042643923240938165,
      "grad_norm": 13.969676971435547,
      "learning_rate": 0.00019797441364605544,
      "loss": 0.6855,
      "step": 20
    },
    {
      "epoch": 0.06396588486140725,
      "grad_norm": 6.078273773193359,
      "learning_rate": 0.000196908315565032,
      "loss": 0.7054,
      "step": 30
    },
    {
      "epoch": 0.08528784648187633,
      "grad_norm": 3.477449893951416,
      "learning_rate": 0.00019584221748400853,
      "loss": 0.5765,
      "step": 40
    },
    {
      "epoch": 0.10660980810234541,
      "grad_norm": 3.3041889667510986,
      "learning_rate": 0.00019477611940298508,
      "loss": 0.7286,
      "step": 50
    },
    {
      "epoch": 0.1279317697228145,
      "grad_norm": 3.147641181945801,
      "learning_rate": 0.00019371002132196163,
      "loss": 0.5026,
      "step": 60
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 5.5203022956848145,
      "learning_rate": 0.00019264392324093817,
      "loss": 0.566,
      "step": 70
    },
    {
      "epoch": 0.17057569296375266,
      "grad_norm": 6.677151203155518,
      "learning_rate": 0.00019157782515991472,
      "loss": 0.5513,
      "step": 80
    },
    {
      "epoch": 0.19189765458422176,
      "grad_norm": 2.017284870147705,
      "learning_rate": 0.00019051172707889127,
      "loss": 0.6117,
      "step": 90
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 9.898077964782715,
      "learning_rate": 0.00018944562899786782,
      "loss": 0.6084,
      "step": 100
    },
    {
      "epoch": 0.21321961620469082,
      "eval_accuracy": 0.861,
      "eval_loss": 0.3464835286140442,
      "eval_runtime": 19.1697,
      "eval_samples_per_second": 104.331,
      "eval_steps_per_second": 13.041,
      "step": 100
    },
    {
      "epoch": 0.2345415778251599,
      "grad_norm": 1.7104098796844482,
      "learning_rate": 0.00018837953091684436,
      "loss": 0.5628,
      "step": 110
    },
    {
      "epoch": 0.255863539445629,
      "grad_norm": 4.790387153625488,
      "learning_rate": 0.0001873134328358209,
      "loss": 0.4975,
      "step": 120
    },
    {
      "epoch": 0.2771855010660981,
      "grad_norm": 7.213485240936279,
      "learning_rate": 0.00018624733475479746,
      "loss": 0.5618,
      "step": 130
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 5.386546611785889,
      "learning_rate": 0.000185181236673774,
      "loss": 0.5714,
      "step": 140
    },
    {
      "epoch": 0.31982942430703626,
      "grad_norm": 3.544647693634033,
      "learning_rate": 0.00018411513859275052,
      "loss": 0.4366,
      "step": 150
    },
    {
      "epoch": 0.3411513859275053,
      "grad_norm": 2.8548061847686768,
      "learning_rate": 0.0001830490405117271,
      "loss": 0.5976,
      "step": 160
    },
    {
      "epoch": 0.3624733475479744,
      "grad_norm": 1.7777255773544312,
      "learning_rate": 0.00018198294243070365,
      "loss": 0.6357,
      "step": 170
    },
    {
      "epoch": 0.3837953091684435,
      "grad_norm": 6.975357532501221,
      "learning_rate": 0.00018091684434968017,
      "loss": 0.5559,
      "step": 180
    },
    {
      "epoch": 0.4051172707889126,
      "grad_norm": 4.034923076629639,
      "learning_rate": 0.00017985074626865671,
      "loss": 0.5085,
      "step": 190
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 2.496473550796509,
      "learning_rate": 0.00017878464818763326,
      "loss": 0.4955,
      "step": 200
    },
    {
      "epoch": 0.42643923240938164,
      "eval_accuracy": 0.536,
      "eval_loss": 0.8488805890083313,
      "eval_runtime": 19.1967,
      "eval_samples_per_second": 104.185,
      "eval_steps_per_second": 13.023,
      "step": 200
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 2.3235082626342773,
      "learning_rate": 0.00017771855010660984,
      "loss": 0.5311,
      "step": 210
    },
    {
      "epoch": 0.4690831556503198,
      "grad_norm": 5.3621673583984375,
      "learning_rate": 0.00017665245202558636,
      "loss": 0.5586,
      "step": 220
    },
    {
      "epoch": 0.4904051172707889,
      "grad_norm": 1.6893384456634521,
      "learning_rate": 0.0001755863539445629,
      "loss": 0.4827,
      "step": 230
    },
    {
      "epoch": 0.511727078891258,
      "grad_norm": 6.385293006896973,
      "learning_rate": 0.00017452025586353945,
      "loss": 0.5026,
      "step": 240
    },
    {
      "epoch": 0.5330490405117271,
      "grad_norm": 4.497021198272705,
      "learning_rate": 0.000173454157782516,
      "loss": 0.5173,
      "step": 250
    },
    {
      "epoch": 0.5543710021321961,
      "grad_norm": 4.323641777038574,
      "learning_rate": 0.00017238805970149255,
      "loss": 0.4529,
      "step": 260
    },
    {
      "epoch": 0.5756929637526652,
      "grad_norm": 1.8378162384033203,
      "learning_rate": 0.0001713219616204691,
      "loss": 0.4519,
      "step": 270
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 6.153743743896484,
      "learning_rate": 0.00017025586353944564,
      "loss": 0.5687,
      "step": 280
    },
    {
      "epoch": 0.6183368869936035,
      "grad_norm": 5.9506611824035645,
      "learning_rate": 0.0001691897654584222,
      "loss": 0.5878,
      "step": 290
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 4.494678020477295,
      "learning_rate": 0.00016812366737739874,
      "loss": 0.4583,
      "step": 300
    },
    {
      "epoch": 0.6396588486140725,
      "eval_accuracy": 0.7985,
      "eval_loss": 0.4173334538936615,
      "eval_runtime": 19.1772,
      "eval_samples_per_second": 104.29,
      "eval_steps_per_second": 13.036,
      "step": 300
    },
    {
      "epoch": 0.6609808102345416,
      "grad_norm": 2.456270217895508,
      "learning_rate": 0.00016705756929637528,
      "loss": 0.452,
      "step": 310
    },
    {
      "epoch": 0.6823027718550106,
      "grad_norm": 2.5520529747009277,
      "learning_rate": 0.0001659914712153518,
      "loss": 0.4194,
      "step": 320
    },
    {
      "epoch": 0.7036247334754797,
      "grad_norm": 3.293727397918701,
      "learning_rate": 0.00016492537313432838,
      "loss": 0.5261,
      "step": 330
    },
    {
      "epoch": 0.7249466950959488,
      "grad_norm": 7.6037211418151855,
      "learning_rate": 0.00016385927505330493,
      "loss": 0.489,
      "step": 340
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 8.811973571777344,
      "learning_rate": 0.00016279317697228145,
      "loss": 0.654,
      "step": 350
    },
    {
      "epoch": 0.767590618336887,
      "grad_norm": 2.5095229148864746,
      "learning_rate": 0.000161727078891258,
      "loss": 0.4301,
      "step": 360
    },
    {
      "epoch": 0.7889125799573561,
      "grad_norm": 2.8071093559265137,
      "learning_rate": 0.00016066098081023454,
      "loss": 0.5005,
      "step": 370
    },
    {
      "epoch": 0.8102345415778252,
      "grad_norm": 2.4361610412597656,
      "learning_rate": 0.00015959488272921111,
      "loss": 0.4458,
      "step": 380
    },
    {
      "epoch": 0.8315565031982942,
      "grad_norm": 10.648269653320312,
      "learning_rate": 0.00015852878464818763,
      "loss": 0.5033,
      "step": 390
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 2.7579569816589355,
      "learning_rate": 0.00015746268656716418,
      "loss": 0.4821,
      "step": 400
    },
    {
      "epoch": 0.8528784648187633,
      "eval_accuracy": 0.7965,
      "eval_loss": 0.42556342482566833,
      "eval_runtime": 19.1511,
      "eval_samples_per_second": 104.433,
      "eval_steps_per_second": 13.054,
      "step": 400
    },
    {
      "epoch": 0.8742004264392325,
      "grad_norm": 10.838558197021484,
      "learning_rate": 0.00015639658848614073,
      "loss": 0.4703,
      "step": 410
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 4.314554214477539,
      "learning_rate": 0.00015533049040511728,
      "loss": 0.4977,
      "step": 420
    },
    {
      "epoch": 0.9168443496801706,
      "grad_norm": 4.210816860198975,
      "learning_rate": 0.00015426439232409382,
      "loss": 0.5009,
      "step": 430
    },
    {
      "epoch": 0.9381663113006397,
      "grad_norm": 7.25962495803833,
      "learning_rate": 0.00015319829424307037,
      "loss": 0.4238,
      "step": 440
    },
    {
      "epoch": 0.9594882729211087,
      "grad_norm": 1.294158697128296,
      "learning_rate": 0.00015213219616204692,
      "loss": 0.4427,
      "step": 450
    },
    {
      "epoch": 0.9808102345415778,
      "grad_norm": 1.7271053791046143,
      "learning_rate": 0.00015106609808102347,
      "loss": 0.4976,
      "step": 460
    },
    {
      "epoch": 1.0021321961620469,
      "grad_norm": 6.471251010894775,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.4943,
      "step": 470
    },
    {
      "epoch": 1.023454157782516,
      "grad_norm": 2.6051461696624756,
      "learning_rate": 0.00014893390191897656,
      "loss": 0.4673,
      "step": 480
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 3.211005926132202,
      "learning_rate": 0.00014786780383795308,
      "loss": 0.5028,
      "step": 490
    },
    {
      "epoch": 1.0660980810234542,
      "grad_norm": 7.52026891708374,
      "learning_rate": 0.00014680170575692963,
      "loss": 0.4376,
      "step": 500
    },
    {
      "epoch": 1.0660980810234542,
      "eval_accuracy": 0.6235,
      "eval_loss": 0.5918454527854919,
      "eval_runtime": 19.1965,
      "eval_samples_per_second": 104.185,
      "eval_steps_per_second": 13.023,
      "step": 500
    },
    {
      "epoch": 1.0874200426439233,
      "grad_norm": 4.986802577972412,
      "learning_rate": 0.0001457356076759062,
      "loss": 0.5268,
      "step": 510
    },
    {
      "epoch": 1.1087420042643923,
      "grad_norm": 5.491006374359131,
      "learning_rate": 0.00014466950959488275,
      "loss": 0.4327,
      "step": 520
    },
    {
      "epoch": 1.1300639658848615,
      "grad_norm": 1.2664027214050293,
      "learning_rate": 0.00014360341151385927,
      "loss": 0.4386,
      "step": 530
    },
    {
      "epoch": 1.1513859275053304,
      "grad_norm": 2.8439688682556152,
      "learning_rate": 0.00014253731343283582,
      "loss": 0.3965,
      "step": 540
    },
    {
      "epoch": 1.1727078891257996,
      "grad_norm": 7.097538948059082,
      "learning_rate": 0.0001414712153518124,
      "loss": 0.4013,
      "step": 550
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 4.737907409667969,
      "learning_rate": 0.0001404051172707889,
      "loss": 0.4943,
      "step": 560
    },
    {
      "epoch": 1.2153518123667377,
      "grad_norm": 7.185183048248291,
      "learning_rate": 0.00013933901918976546,
      "loss": 0.5249,
      "step": 570
    },
    {
      "epoch": 1.236673773987207,
      "grad_norm": 4.880934238433838,
      "learning_rate": 0.000138272921108742,
      "loss": 0.5122,
      "step": 580
    },
    {
      "epoch": 1.2579957356076759,
      "grad_norm": 2.8607583045959473,
      "learning_rate": 0.00013720682302771856,
      "loss": 0.4676,
      "step": 590
    },
    {
      "epoch": 1.279317697228145,
      "grad_norm": 5.243624687194824,
      "learning_rate": 0.0001361407249466951,
      "loss": 0.5144,
      "step": 600
    },
    {
      "epoch": 1.279317697228145,
      "eval_accuracy": 0.858,
      "eval_loss": 0.33195915818214417,
      "eval_runtime": 19.1221,
      "eval_samples_per_second": 104.591,
      "eval_steps_per_second": 13.074,
      "step": 600
    },
    {
      "epoch": 1.3006396588486142,
      "grad_norm": 5.732856273651123,
      "learning_rate": 0.00013507462686567165,
      "loss": 0.5333,
      "step": 610
    },
    {
      "epoch": 1.3219616204690832,
      "grad_norm": 2.060080051422119,
      "learning_rate": 0.0001340085287846482,
      "loss": 0.5592,
      "step": 620
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 4.4648871421813965,
      "learning_rate": 0.00013294243070362474,
      "loss": 0.4283,
      "step": 630
    },
    {
      "epoch": 1.3646055437100213,
      "grad_norm": 4.493460655212402,
      "learning_rate": 0.0001318763326226013,
      "loss": 0.3901,
      "step": 640
    },
    {
      "epoch": 1.3859275053304905,
      "grad_norm": 2.271259307861328,
      "learning_rate": 0.00013081023454157784,
      "loss": 0.5007,
      "step": 650
    },
    {
      "epoch": 1.4072494669509594,
      "grad_norm": 3.6610031127929688,
      "learning_rate": 0.00012974413646055436,
      "loss": 0.3973,
      "step": 660
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 3.9350264072418213,
      "learning_rate": 0.0001286780383795309,
      "loss": 0.5364,
      "step": 670
    },
    {
      "epoch": 1.4498933901918978,
      "grad_norm": 1.6100420951843262,
      "learning_rate": 0.00012761194029850748,
      "loss": 0.4182,
      "step": 680
    },
    {
      "epoch": 1.4712153518123667,
      "grad_norm": 3.0793888568878174,
      "learning_rate": 0.00012654584221748403,
      "loss": 0.4346,
      "step": 690
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 4.500609874725342,
      "learning_rate": 0.00012547974413646055,
      "loss": 0.4286,
      "step": 700
    },
    {
      "epoch": 1.4925373134328357,
      "eval_accuracy": 0.7435,
      "eval_loss": 0.49591901898384094,
      "eval_runtime": 19.1286,
      "eval_samples_per_second": 104.556,
      "eval_steps_per_second": 13.069,
      "step": 700
    },
    {
      "epoch": 1.5138592750533049,
      "grad_norm": 7.464279651641846,
      "learning_rate": 0.0001244136460554371,
      "loss": 0.368,
      "step": 710
    },
    {
      "epoch": 1.535181236673774,
      "grad_norm": 2.816497802734375,
      "learning_rate": 0.00012334754797441364,
      "loss": 0.4934,
      "step": 720
    },
    {
      "epoch": 1.556503198294243,
      "grad_norm": 2.1642308235168457,
      "learning_rate": 0.0001222814498933902,
      "loss": 0.4472,
      "step": 730
    },
    {
      "epoch": 1.5778251599147122,
      "grad_norm": 3.3321051597595215,
      "learning_rate": 0.00012121535181236674,
      "loss": 0.4603,
      "step": 740
    },
    {
      "epoch": 1.5991471215351813,
      "grad_norm": 3.1405560970306396,
      "learning_rate": 0.00012014925373134329,
      "loss": 0.3812,
      "step": 750
    },
    {
      "epoch": 1.6204690831556503,
      "grad_norm": 5.101654529571533,
      "learning_rate": 0.00011908315565031985,
      "loss": 0.4185,
      "step": 760
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 4.834927082061768,
      "learning_rate": 0.00011801705756929637,
      "loss": 0.448,
      "step": 770
    },
    {
      "epoch": 1.6631130063965884,
      "grad_norm": 3.2333123683929443,
      "learning_rate": 0.00011695095948827293,
      "loss": 0.4065,
      "step": 780
    },
    {
      "epoch": 1.6844349680170576,
      "grad_norm": 4.776906967163086,
      "learning_rate": 0.00011588486140724948,
      "loss": 0.4355,
      "step": 790
    },
    {
      "epoch": 1.7057569296375266,
      "grad_norm": 3.8363451957702637,
      "learning_rate": 0.00011481876332622601,
      "loss": 0.4308,
      "step": 800
    },
    {
      "epoch": 1.7057569296375266,
      "eval_accuracy": 0.737,
      "eval_loss": 0.5470160841941833,
      "eval_runtime": 19.683,
      "eval_samples_per_second": 101.611,
      "eval_steps_per_second": 12.701,
      "step": 800
    },
    {
      "epoch": 1.7270788912579957,
      "grad_norm": 3.450916290283203,
      "learning_rate": 0.00011375266524520256,
      "loss": 0.4442,
      "step": 810
    },
    {
      "epoch": 1.748400852878465,
      "grad_norm": 2.1463141441345215,
      "learning_rate": 0.00011268656716417912,
      "loss": 0.4352,
      "step": 820
    },
    {
      "epoch": 1.7697228144989339,
      "grad_norm": 4.042328834533691,
      "learning_rate": 0.00011162046908315567,
      "loss": 0.4383,
      "step": 830
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 3.7896173000335693,
      "learning_rate": 0.0001105543710021322,
      "loss": 0.3669,
      "step": 840
    },
    {
      "epoch": 1.8123667377398722,
      "grad_norm": 2.7799925804138184,
      "learning_rate": 0.00010948827292110875,
      "loss": 0.412,
      "step": 850
    },
    {
      "epoch": 1.8336886993603412,
      "grad_norm": 2.6770741939544678,
      "learning_rate": 0.0001084221748400853,
      "loss": 0.3478,
      "step": 860
    },
    {
      "epoch": 1.8550106609808101,
      "grad_norm": 2.5992825031280518,
      "learning_rate": 0.00010735607675906183,
      "loss": 0.3847,
      "step": 870
    },
    {
      "epoch": 1.8763326226012793,
      "grad_norm": 5.550915718078613,
      "learning_rate": 0.00010628997867803839,
      "loss": 0.3287,
      "step": 880
    },
    {
      "epoch": 1.8976545842217485,
      "grad_norm": 3.445614814758301,
      "learning_rate": 0.00010522388059701494,
      "loss": 0.4333,
      "step": 890
    },
    {
      "epoch": 1.9189765458422174,
      "grad_norm": 4.1521477699279785,
      "learning_rate": 0.00010415778251599148,
      "loss": 0.3818,
      "step": 900
    },
    {
      "epoch": 1.9189765458422174,
      "eval_accuracy": 0.8445,
      "eval_loss": 0.33817005157470703,
      "eval_runtime": 20.616,
      "eval_samples_per_second": 97.012,
      "eval_steps_per_second": 12.126,
      "step": 900
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 2.3322060108184814,
      "learning_rate": 0.00010309168443496802,
      "loss": 0.4204,
      "step": 910
    },
    {
      "epoch": 1.9616204690831558,
      "grad_norm": 3.991548776626587,
      "learning_rate": 0.00010202558635394456,
      "loss": 0.4497,
      "step": 920
    },
    {
      "epoch": 1.9829424307036247,
      "grad_norm": 2.6819353103637695,
      "learning_rate": 0.00010095948827292113,
      "loss": 0.5334,
      "step": 930
    },
    {
      "epoch": 2.0042643923240937,
      "grad_norm": 3.4084219932556152,
      "learning_rate": 9.989339019189766e-05,
      "loss": 0.4834,
      "step": 940
    },
    {
      "epoch": 2.025586353944563,
      "grad_norm": 3.0030558109283447,
      "learning_rate": 9.882729211087421e-05,
      "loss": 0.4065,
      "step": 950
    },
    {
      "epoch": 2.046908315565032,
      "grad_norm": 3.6578125953674316,
      "learning_rate": 9.776119402985075e-05,
      "loss": 0.3257,
      "step": 960
    },
    {
      "epoch": 2.068230277185501,
      "grad_norm": 8.2940034866333,
      "learning_rate": 9.66950959488273e-05,
      "loss": 0.4805,
      "step": 970
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 4.152525424957275,
      "learning_rate": 9.562899786780384e-05,
      "loss": 0.3914,
      "step": 980
    },
    {
      "epoch": 2.1108742004264394,
      "grad_norm": 5.026083469390869,
      "learning_rate": 9.45628997867804e-05,
      "loss": 0.492,
      "step": 990
    },
    {
      "epoch": 2.1321961620469083,
      "grad_norm": 3.2899022102355957,
      "learning_rate": 9.349680170575693e-05,
      "loss": 0.3623,
      "step": 1000
    },
    {
      "epoch": 2.1321961620469083,
      "eval_accuracy": 0.9055,
      "eval_loss": 0.24711766839027405,
      "eval_runtime": 19.3258,
      "eval_samples_per_second": 103.489,
      "eval_steps_per_second": 12.936,
      "step": 1000
    },
    {
      "epoch": 2.1535181236673773,
      "grad_norm": 4.235232353210449,
      "learning_rate": 9.243070362473348e-05,
      "loss": 0.4266,
      "step": 1010
    },
    {
      "epoch": 2.1748400852878467,
      "grad_norm": 4.101809978485107,
      "learning_rate": 9.136460554371003e-05,
      "loss": 0.3898,
      "step": 1020
    },
    {
      "epoch": 2.1961620469083156,
      "grad_norm": 5.0499114990234375,
      "learning_rate": 9.029850746268657e-05,
      "loss": 0.3518,
      "step": 1030
    },
    {
      "epoch": 2.2174840085287846,
      "grad_norm": 3.8366241455078125,
      "learning_rate": 8.923240938166312e-05,
      "loss": 0.4141,
      "step": 1040
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 6.012579917907715,
      "learning_rate": 8.816631130063965e-05,
      "loss": 0.3718,
      "step": 1050
    },
    {
      "epoch": 2.260127931769723,
      "grad_norm": 1.6133345365524292,
      "learning_rate": 8.710021321961621e-05,
      "loss": 0.4059,
      "step": 1060
    },
    {
      "epoch": 2.281449893390192,
      "grad_norm": 3.7620880603790283,
      "learning_rate": 8.603411513859275e-05,
      "loss": 0.3863,
      "step": 1070
    },
    {
      "epoch": 2.302771855010661,
      "grad_norm": 3.1479692459106445,
      "learning_rate": 8.496801705756931e-05,
      "loss": 0.4133,
      "step": 1080
    },
    {
      "epoch": 2.3240938166311302,
      "grad_norm": 4.700605869293213,
      "learning_rate": 8.390191897654584e-05,
      "loss": 0.3597,
      "step": 1090
    },
    {
      "epoch": 2.345415778251599,
      "grad_norm": 2.8537871837615967,
      "learning_rate": 8.283582089552239e-05,
      "loss": 0.3916,
      "step": 1100
    },
    {
      "epoch": 2.345415778251599,
      "eval_accuracy": 0.838,
      "eval_loss": 0.37122681736946106,
      "eval_runtime": 19.6679,
      "eval_samples_per_second": 101.689,
      "eval_steps_per_second": 12.711,
      "step": 1100
    },
    {
      "epoch": 2.366737739872068,
      "grad_norm": 3.012627124786377,
      "learning_rate": 8.176972281449894e-05,
      "loss": 0.4458,
      "step": 1110
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 2.834637403488159,
      "learning_rate": 8.070362473347549e-05,
      "loss": 0.4099,
      "step": 1120
    },
    {
      "epoch": 2.4093816631130065,
      "grad_norm": 6.758070945739746,
      "learning_rate": 7.963752665245203e-05,
      "loss": 0.4158,
      "step": 1130
    },
    {
      "epoch": 2.4307036247334755,
      "grad_norm": 5.080770969390869,
      "learning_rate": 7.857142857142858e-05,
      "loss": 0.4349,
      "step": 1140
    },
    {
      "epoch": 2.4520255863539444,
      "grad_norm": 2.6886677742004395,
      "learning_rate": 7.750533049040513e-05,
      "loss": 0.3927,
      "step": 1150
    },
    {
      "epoch": 2.473347547974414,
      "grad_norm": 2.950552225112915,
      "learning_rate": 7.643923240938166e-05,
      "loss": 0.4013,
      "step": 1160
    },
    {
      "epoch": 2.4946695095948828,
      "grad_norm": 7.9923176765441895,
      "learning_rate": 7.537313432835821e-05,
      "loss": 0.3573,
      "step": 1170
    },
    {
      "epoch": 2.5159914712153517,
      "grad_norm": 3.4905788898468018,
      "learning_rate": 7.430703624733476e-05,
      "loss": 0.3204,
      "step": 1180
    },
    {
      "epoch": 2.5373134328358207,
      "grad_norm": 4.865111827850342,
      "learning_rate": 7.32409381663113e-05,
      "loss": 0.3519,
      "step": 1190
    },
    {
      "epoch": 2.55863539445629,
      "grad_norm": 6.8209757804870605,
      "learning_rate": 7.217484008528785e-05,
      "loss": 0.4601,
      "step": 1200
    },
    {
      "epoch": 2.55863539445629,
      "eval_accuracy": 0.776,
      "eval_loss": 0.4375900328159332,
      "eval_runtime": 19.7033,
      "eval_samples_per_second": 101.506,
      "eval_steps_per_second": 12.688,
      "step": 1200
    },
    {
      "epoch": 2.579957356076759,
      "grad_norm": 4.946341514587402,
      "learning_rate": 7.11087420042644e-05,
      "loss": 0.5039,
      "step": 1210
    },
    {
      "epoch": 2.6012793176972284,
      "grad_norm": 4.222741603851318,
      "learning_rate": 7.004264392324095e-05,
      "loss": 0.407,
      "step": 1220
    },
    {
      "epoch": 2.6226012793176974,
      "grad_norm": 3.4670181274414062,
      "learning_rate": 6.897654584221749e-05,
      "loss": 0.4335,
      "step": 1230
    },
    {
      "epoch": 2.6439232409381663,
      "grad_norm": 4.0888519287109375,
      "learning_rate": 6.791044776119403e-05,
      "loss": 0.3413,
      "step": 1240
    },
    {
      "epoch": 2.6652452025586353,
      "grad_norm": 7.230747699737549,
      "learning_rate": 6.684434968017059e-05,
      "loss": 0.3536,
      "step": 1250
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 9.03535270690918,
      "learning_rate": 6.577825159914712e-05,
      "loss": 0.4123,
      "step": 1260
    },
    {
      "epoch": 2.7078891257995736,
      "grad_norm": 2.8373241424560547,
      "learning_rate": 6.471215351812367e-05,
      "loss": 0.3719,
      "step": 1270
    },
    {
      "epoch": 2.7292110874200426,
      "grad_norm": 2.548849105834961,
      "learning_rate": 6.364605543710022e-05,
      "loss": 0.419,
      "step": 1280
    },
    {
      "epoch": 2.750533049040512,
      "grad_norm": 2.0839805603027344,
      "learning_rate": 6.257995735607676e-05,
      "loss": 0.3839,
      "step": 1290
    },
    {
      "epoch": 2.771855010660981,
      "grad_norm": 1.9694875478744507,
      "learning_rate": 6.151385927505331e-05,
      "loss": 0.3353,
      "step": 1300
    },
    {
      "epoch": 2.771855010660981,
      "eval_accuracy": 0.8765,
      "eval_loss": 0.2823418080806732,
      "eval_runtime": 20.6418,
      "eval_samples_per_second": 96.891,
      "eval_steps_per_second": 12.111,
      "step": 1300
    },
    {
      "epoch": 2.79317697228145,
      "grad_norm": 4.512228965759277,
      "learning_rate": 6.044776119402985e-05,
      "loss": 0.2964,
      "step": 1310
    },
    {
      "epoch": 2.814498933901919,
      "grad_norm": 3.196049213409424,
      "learning_rate": 5.9381663113006406e-05,
      "loss": 0.402,
      "step": 1320
    },
    {
      "epoch": 2.835820895522388,
      "grad_norm": 3.4832422733306885,
      "learning_rate": 5.8315565031982946e-05,
      "loss": 0.3428,
      "step": 1330
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.7065691947937012,
      "learning_rate": 5.7249466950959494e-05,
      "loss": 0.4347,
      "step": 1340
    },
    {
      "epoch": 2.878464818763326,
      "grad_norm": 3.4494729042053223,
      "learning_rate": 5.6183368869936034e-05,
      "loss": 0.4394,
      "step": 1350
    },
    {
      "epoch": 2.8997867803837956,
      "grad_norm": 4.7088623046875,
      "learning_rate": 5.5117270788912575e-05,
      "loss": 0.3863,
      "step": 1360
    },
    {
      "epoch": 2.9211087420042645,
      "grad_norm": 3.3807871341705322,
      "learning_rate": 5.405117270788913e-05,
      "loss": 0.3998,
      "step": 1370
    },
    {
      "epoch": 2.9424307036247335,
      "grad_norm": 3.1269569396972656,
      "learning_rate": 5.298507462686567e-05,
      "loss": 0.4782,
      "step": 1380
    },
    {
      "epoch": 2.9637526652452024,
      "grad_norm": 2.401632070541382,
      "learning_rate": 5.1918976545842224e-05,
      "loss": 0.3542,
      "step": 1390
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 4.100166320800781,
      "learning_rate": 5.0852878464818764e-05,
      "loss": 0.3904,
      "step": 1400
    },
    {
      "epoch": 2.9850746268656714,
      "eval_accuracy": 0.8175,
      "eval_loss": 0.40432459115982056,
      "eval_runtime": 19.9183,
      "eval_samples_per_second": 100.41,
      "eval_steps_per_second": 12.551,
      "step": 1400
    },
    {
      "epoch": 3.0063965884861408,
      "grad_norm": 2.6594982147216797,
      "learning_rate": 4.978678038379531e-05,
      "loss": 0.3418,
      "step": 1410
    },
    {
      "epoch": 3.0277185501066097,
      "grad_norm": 6.93410062789917,
      "learning_rate": 4.872068230277186e-05,
      "loss": 0.4069,
      "step": 1420
    },
    {
      "epoch": 3.0490405117270787,
      "grad_norm": 2.5766305923461914,
      "learning_rate": 4.765458422174841e-05,
      "loss": 0.3451,
      "step": 1430
    },
    {
      "epoch": 3.070362473347548,
      "grad_norm": 3.2058956623077393,
      "learning_rate": 4.658848614072495e-05,
      "loss": 0.3122,
      "step": 1440
    },
    {
      "epoch": 3.091684434968017,
      "grad_norm": 3.4201853275299072,
      "learning_rate": 4.5522388059701495e-05,
      "loss": 0.4047,
      "step": 1450
    },
    {
      "epoch": 3.113006396588486,
      "grad_norm": 4.004755020141602,
      "learning_rate": 4.445628997867804e-05,
      "loss": 0.4784,
      "step": 1460
    },
    {
      "epoch": 3.1343283582089554,
      "grad_norm": 4.191372394561768,
      "learning_rate": 4.339019189765459e-05,
      "loss": 0.2773,
      "step": 1470
    },
    {
      "epoch": 3.1556503198294243,
      "grad_norm": 2.903263807296753,
      "learning_rate": 4.232409381663113e-05,
      "loss": 0.3155,
      "step": 1480
    },
    {
      "epoch": 3.1769722814498933,
      "grad_norm": 7.854856967926025,
      "learning_rate": 4.125799573560768e-05,
      "loss": 0.354,
      "step": 1490
    },
    {
      "epoch": 3.1982942430703627,
      "grad_norm": 4.73897123336792,
      "learning_rate": 4.0191897654584225e-05,
      "loss": 0.2817,
      "step": 1500
    },
    {
      "epoch": 3.1982942430703627,
      "eval_accuracy": 0.852,
      "eval_loss": 0.3528019189834595,
      "eval_runtime": 19.365,
      "eval_samples_per_second": 103.279,
      "eval_steps_per_second": 12.91,
      "step": 1500
    },
    {
      "epoch": 3.2196162046908317,
      "grad_norm": 4.689615726470947,
      "learning_rate": 3.9125799573560765e-05,
      "loss": 0.4148,
      "step": 1510
    },
    {
      "epoch": 3.2409381663113006,
      "grad_norm": 3.847822427749634,
      "learning_rate": 3.805970149253731e-05,
      "loss": 0.4177,
      "step": 1520
    },
    {
      "epoch": 3.2622601279317696,
      "grad_norm": 5.47418737411499,
      "learning_rate": 3.699360341151386e-05,
      "loss": 0.2738,
      "step": 1530
    },
    {
      "epoch": 3.283582089552239,
      "grad_norm": 2.5634961128234863,
      "learning_rate": 3.592750533049041e-05,
      "loss": 0.3211,
      "step": 1540
    },
    {
      "epoch": 3.304904051172708,
      "grad_norm": 2.118511199951172,
      "learning_rate": 3.4861407249466955e-05,
      "loss": 0.3454,
      "step": 1550
    },
    {
      "epoch": 3.326226012793177,
      "grad_norm": 4.2174153327941895,
      "learning_rate": 3.37953091684435e-05,
      "loss": 0.3454,
      "step": 1560
    },
    {
      "epoch": 3.3475479744136463,
      "grad_norm": 11.813124656677246,
      "learning_rate": 3.272921108742004e-05,
      "loss": 0.3785,
      "step": 1570
    },
    {
      "epoch": 3.368869936034115,
      "grad_norm": 1.897312879562378,
      "learning_rate": 3.166311300639659e-05,
      "loss": 0.4038,
      "step": 1580
    },
    {
      "epoch": 3.390191897654584,
      "grad_norm": 3.1357789039611816,
      "learning_rate": 3.059701492537314e-05,
      "loss": 0.3654,
      "step": 1590
    },
    {
      "epoch": 3.411513859275053,
      "grad_norm": 3.199032783508301,
      "learning_rate": 2.953091684434968e-05,
      "loss": 0.3164,
      "step": 1600
    },
    {
      "epoch": 3.411513859275053,
      "eval_accuracy": 0.888,
      "eval_loss": 0.2796670198440552,
      "eval_runtime": 19.371,
      "eval_samples_per_second": 103.247,
      "eval_steps_per_second": 12.906,
      "step": 1600
    },
    {
      "epoch": 3.4328358208955225,
      "grad_norm": 2.577512741088867,
      "learning_rate": 2.846481876332623e-05,
      "loss": 0.3706,
      "step": 1610
    },
    {
      "epoch": 3.4541577825159915,
      "grad_norm": 4.8482985496521,
      "learning_rate": 2.7398720682302776e-05,
      "loss": 0.4734,
      "step": 1620
    },
    {
      "epoch": 3.4754797441364604,
      "grad_norm": 2.436969518661499,
      "learning_rate": 2.6332622601279317e-05,
      "loss": 0.3434,
      "step": 1630
    },
    {
      "epoch": 3.49680170575693,
      "grad_norm": 5.341362476348877,
      "learning_rate": 2.5266524520255864e-05,
      "loss": 0.3509,
      "step": 1640
    },
    {
      "epoch": 3.518123667377399,
      "grad_norm": 2.402466058731079,
      "learning_rate": 2.420042643923241e-05,
      "loss": 0.4199,
      "step": 1650
    },
    {
      "epoch": 3.5394456289978677,
      "grad_norm": 1.4611437320709229,
      "learning_rate": 2.3134328358208956e-05,
      "loss": 0.3306,
      "step": 1660
    },
    {
      "epoch": 3.5607675906183367,
      "grad_norm": 3.6609365940093994,
      "learning_rate": 2.2068230277185503e-05,
      "loss": 0.3069,
      "step": 1670
    },
    {
      "epoch": 3.582089552238806,
      "grad_norm": 3.2400453090667725,
      "learning_rate": 2.1002132196162047e-05,
      "loss": 0.4167,
      "step": 1680
    },
    {
      "epoch": 3.603411513859275,
      "grad_norm": 3.1382577419281006,
      "learning_rate": 1.9936034115138594e-05,
      "loss": 0.3708,
      "step": 1690
    },
    {
      "epoch": 3.624733475479744,
      "grad_norm": 4.770206928253174,
      "learning_rate": 1.8869936034115142e-05,
      "loss": 0.4023,
      "step": 1700
    },
    {
      "epoch": 3.624733475479744,
      "eval_accuracy": 0.854,
      "eval_loss": 0.3288516104221344,
      "eval_runtime": 20.4765,
      "eval_samples_per_second": 97.673,
      "eval_steps_per_second": 12.209,
      "step": 1700
    },
    {
      "epoch": 3.6460554371002134,
      "grad_norm": 3.9605038166046143,
      "learning_rate": 1.7803837953091686e-05,
      "loss": 0.3998,
      "step": 1710
    },
    {
      "epoch": 3.6673773987206824,
      "grad_norm": 2.377464532852173,
      "learning_rate": 1.673773987206823e-05,
      "loss": 0.3164,
      "step": 1720
    },
    {
      "epoch": 3.6886993603411513,
      "grad_norm": 4.243930816650391,
      "learning_rate": 1.5671641791044777e-05,
      "loss": 0.3368,
      "step": 1730
    },
    {
      "epoch": 3.7100213219616203,
      "grad_norm": 3.2894163131713867,
      "learning_rate": 1.4605543710021321e-05,
      "loss": 0.4344,
      "step": 1740
    },
    {
      "epoch": 3.7313432835820897,
      "grad_norm": 3.6238813400268555,
      "learning_rate": 1.3539445628997869e-05,
      "loss": 0.3792,
      "step": 1750
    },
    {
      "epoch": 3.7526652452025586,
      "grad_norm": 4.335221767425537,
      "learning_rate": 1.2473347547974414e-05,
      "loss": 0.4025,
      "step": 1760
    },
    {
      "epoch": 3.7739872068230276,
      "grad_norm": 3.9669764041900635,
      "learning_rate": 1.140724946695096e-05,
      "loss": 0.3734,
      "step": 1770
    },
    {
      "epoch": 3.795309168443497,
      "grad_norm": 2.1876587867736816,
      "learning_rate": 1.0341151385927506e-05,
      "loss": 0.2979,
      "step": 1780
    },
    {
      "epoch": 3.816631130063966,
      "grad_norm": 5.567675590515137,
      "learning_rate": 9.275053304904053e-06,
      "loss": 0.3891,
      "step": 1790
    },
    {
      "epoch": 3.837953091684435,
      "grad_norm": 2.873570203781128,
      "learning_rate": 8.208955223880597e-06,
      "loss": 0.3598,
      "step": 1800
    },
    {
      "epoch": 3.837953091684435,
      "eval_accuracy": 0.8525,
      "eval_loss": 0.3279194235801697,
      "eval_runtime": 19.6309,
      "eval_samples_per_second": 101.88,
      "eval_steps_per_second": 12.735,
      "step": 1800
    },
    {
      "epoch": 3.859275053304904,
      "grad_norm": 3.383476972579956,
      "learning_rate": 7.142857142857143e-06,
      "loss": 0.2926,
      "step": 1810
    },
    {
      "epoch": 3.8805970149253732,
      "grad_norm": 3.0927438735961914,
      "learning_rate": 6.076759061833688e-06,
      "loss": 0.3588,
      "step": 1820
    },
    {
      "epoch": 3.901918976545842,
      "grad_norm": 3.6154110431671143,
      "learning_rate": 5.010660980810235e-06,
      "loss": 0.3079,
      "step": 1830
    },
    {
      "epoch": 3.923240938166311,
      "grad_norm": 6.1296162605285645,
      "learning_rate": 3.944562899786781e-06,
      "loss": 0.3278,
      "step": 1840
    },
    {
      "epoch": 3.9445628997867805,
      "grad_norm": 3.840804100036621,
      "learning_rate": 2.8784648187633263e-06,
      "loss": 0.2905,
      "step": 1850
    },
    {
      "epoch": 3.9658848614072495,
      "grad_norm": 3.8514130115509033,
      "learning_rate": 1.812366737739872e-06,
      "loss": 0.3276,
      "step": 1860
    },
    {
      "epoch": 3.9872068230277184,
      "grad_norm": 2.7726428508758545,
      "learning_rate": 7.462686567164179e-07,
      "loss": 0.3396,
      "step": 1870
    },
    {
      "epoch": 4.0,
      "step": 1876,
      "total_flos": 2.9941027135488e+17,
      "train_loss": 0.4332856181969266,
      "train_runtime": 2794.5351,
      "train_samples_per_second": 21.47,
      "train_steps_per_second": 0.671
    }
  ],
  "logging_steps": 10,
  "max_steps": 1876,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9941027135488e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
